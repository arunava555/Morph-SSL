{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "sys.path.append(os.getcwd()+'/model/')\n",
    "sys.path.append(os.getcwd()+'/losses/')\n",
    "sys.path.append(os.getcwd()+'/Dataloader/')\n",
    "\n",
    "\n",
    "from Encoder_model import *\n",
    "from Decoder_model import *\n",
    "from Comparator_model import *\n",
    "from Dense_Spatial_Transformation import * \n",
    "from MorphSSL_dataloader import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The perceptual Loss: MSE in the feature space using the comparator network\n",
    "'''\n",
    "############## Compute Perceptual Loss #############\n",
    "def update_perceptual_model():\n",
    "    # uses global perceptual_model, encoder_model.\n",
    "    # The exponential moving average of first few layers of encoder weigths is used to update the comparator network\n",
    "    beta=0.99\n",
    "    for perc_params, enc_params in zip(comparator_model.parameters(), encoder_model.parameters()):\n",
    "        old_wt, new_wt=perc_params.data, enc_params.data\n",
    "        perc_params.data=(old_wt*beta)+(1.0-beta)*new_wt\n",
    "        \n",
    "    \n",
    "\n",
    "def compute_perceptual_loss(I_AB, I_B):\n",
    "    \n",
    "    ####################################################################################\n",
    "    # Update discriminator as a momentum encoder of first few layers of the encoder model\n",
    "    update_perceptual_model()\n",
    "    \n",
    "    #####################################################################################\n",
    "    # Now compute the loss for training our architecture. Architecture must be able to fool, so reverse gt\n",
    "    ftr_AB=comparator_model(I_AB)\n",
    "    ftr_B=comparator_model(I_B)\n",
    "    loss=(F.mse_loss(ftr_AB[0], ftr_B[0])+ F.mse_loss(ftr_AB[1], ftr_B[1]) + F.mse_loss(ftr_AB[2], ftr_B[2]))/3\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b1d0fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50095f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(I_A, I_B, IA_msk, IB_msk):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ftr_A=encoder_model(I_A) # time t\n",
    "        ftr_B=encoder_model(I_B) # time t+k\n",
    "    \n",
    "    D_AB, C_AB=decoder_model(ftr_A, ftr_B)\n",
    "    \n",
    "    I_out, _=spatial_transform(I_A, D_AB, grid_4,'nearest')\n",
    "    I_out=I_out+C_AB\n",
    "    I_AB_msk,_=spatial_transform(IA_msk, D_AB, grid_4,'nearest')\n",
    "    \n",
    "    loss=F.mse_loss((I_out*I_AB_msk),(I_B*IB_msk))# Registration/Metamorphosis loss\n",
    "    loss=loss.detach().cpu().numpy()\n",
    "    return loss\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def complete_inference(val_loader):\n",
    "    t = time.time()\n",
    "\n",
    "    decoder_model.eval()\n",
    "    encoder_model.eval()\n",
    "    loss_lst=[]\n",
    "    lbl_lst=[]\n",
    "    for i, sample in enumerate(val_loader):\n",
    "                \n",
    "        I_A=sample['I_A']\n",
    "        I_B=sample['I_B']\n",
    "        IA_msk=sample['IA_msk']\n",
    "        IB_msk=sample['IB_msk']\n",
    "        \n",
    "        lbl=sample['lbl']\n",
    "        lbl_lst.append(lbl[0])\n",
    "        \n",
    "        nm_A=sample['nm_A'][0]\n",
    "        nm_B=sample['nm_B'][0]\n",
    "                \n",
    "        I_A=I_A.to(device)\n",
    "        I_B=I_B.to(device)\n",
    "        IA_msk=IA_msk.to(device)\n",
    "        IB_msk=IB_msk.to(device)\n",
    "        \n",
    "        loss=inference(I_A, I_B,IA_msk,IB_msk)\n",
    "        loss_lst.append(loss)\n",
    "        del I_A, I_B,loss, IA_msk, IB_msk\n",
    "    \n",
    "    decoder_model.train()\n",
    "    encoder_model.train()\n",
    "    \n",
    "    loss_lst=np.array(loss_lst)\n",
    "    lbl_lst=np.array(lbl_lst)\n",
    "    \n",
    "    run_loss=0\n",
    "    for k in range(0,16):\n",
    "        idx=np.where(lbl_lst==k)\n",
    "        tmp=loss_lst[idx]\n",
    "        del idx\n",
    "        tmp=np.mean(tmp)\n",
    "        run_loss=run_loss+tmp\n",
    "        del tmp\n",
    "        \n",
    "    run_loss=run_loss/16\n",
    "        \n",
    "    print('Validation loss: '+str(run_loss))\n",
    "    print('Validation time is '+str(time.time() - t) +' seconds')\n",
    "    return -run_loss # metric is neg of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3b54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296421d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fe427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_batch(I_A, I_B, IA_msk, IB_msk, opt_enc, opt_dec, sched_enc, sched_dec): \n",
    "    \n",
    "    # Forward pass: get feature representation of the images\n",
    "    ftr_A=encoder_model(I_A) # time t\n",
    "    ftr_B=encoder_model(I_B) # time t+k\n",
    "    \n",
    "    # Predict deformation \n",
    "    D_AB, C_AB=decoder_model(ftr_A, ftr_B)\n",
    "    \n",
    "    \n",
    "    ## Apply deformation to image\n",
    "    I_AB_dfrm, fld_loss=spatial_transform(I_A, D_AB, grid_4,'bilinear')\n",
    "    I_AB_dfrm_nearest, _=spatial_transform(I_A, D_AB, grid_4,'nearest')\n",
    "    \n",
    "    ## Apply deformation to ROI mask\n",
    "    I_AB_msk,_=spatial_transform(IA_msk, D_AB, grid_4,'bilinear')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ########## Compute loss ####################\n",
    "    ## reg error for D_AB\n",
    "    reg_loss_dfrm=F.mse_loss((I_AB_dfrm*I_AB_msk),(I_B*IB_msk))\n",
    "    \n",
    "    ## reg error of C_AB\n",
    "    residual_gt=(I_B-I_AB_dfrm_nearest)*IB_msk\n",
    "    reg_loss_add=F.mse_loss(C_AB, residual_gt)\n",
    "    \n",
    "    ## Cyclic/Discriminator/Perceptual\n",
    "    I_AB=(I_AB_dfrm+C_AB)    \n",
    "    dscrm_loss_img=compute_perceptual_loss(I_AB*I_AB_msk, I_B*IB_msk)\n",
    "    \n",
    "    # Compute smoothness loss\n",
    "    dfrm_smth_loss=comp_smooth_loss(D_AB)# Smoothness of deformation field.\n",
    "    \n",
    "    # Compute L1 sparsity loss for C_AB\n",
    "    add_l1_loss=torch.mean(torch.abs(torch.flatten(C_AB)))\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    ########################## Weight all losses and aggregate ##########\n",
    "    reg_loss_dfrm=(10.0**1)*(reg_loss_dfrm) # 1 \n",
    "    reg_loss_add=(10.0**2)*(reg_loss_add)   # 2 \n",
    "    dscrm_loss_img=dscrm_loss_img*(10**1)   # 1 # 0\n",
    "    ############\n",
    "    fld_loss=(10.0**6)*fld_loss             # 6 # 5\n",
    "    dfrm_smth_loss=(10**-1)*dfrm_smth_loss   # 0 #-1\n",
    "    add_l1_loss=(10.0**-5)*add_l1_loss      # -5\n",
    "    \n",
    "    loss=(reg_loss_dfrm+reg_loss_add+dscrm_loss_img)+(fld_loss+dfrm_smth_loss+add_l1_loss)\n",
    "    \n",
    "    \n",
    "    ###################### Backpropagation ###########################\n",
    "    # remove previous gradients\n",
    "    opt_enc.zero_grad() \n",
    "    opt_dec.zero_grad()\n",
    "    \n",
    "    # compute the gradients\n",
    "    loss.backward() \n",
    "    \n",
    "    # update the weights\n",
    "    opt_enc.step() \n",
    "    opt_dec.step()\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    sched_enc.step() \n",
    "    sched_dec.step()\n",
    "    \n",
    "    ########## Return loss values to Log & Display ##############\n",
    "    loss=loss.detach().cpu().numpy()\n",
    "    reg_loss_dfrm=reg_loss_dfrm.detach().cpu().numpy()\n",
    "    reg_loss_add=reg_loss_add.detach().cpu().numpy()\n",
    "    dscrm_loss_img=dscrm_loss_img.detach().cpu().numpy()\n",
    "    \n",
    "    fld_loss=fld_loss.detach().cpu().numpy()\n",
    "    dfrm_smth_loss=dfrm_smth_loss.detach().cpu().numpy()\n",
    "    add_l1_loss=add_l1_loss.detach().cpu().numpy()\n",
    "    \n",
    "    return loss, reg_loss_dfrm, reg_loss_add,dscrm_loss_img,fld_loss,dfrm_smth_loss,add_l1_loss,\\\n",
    "opt_enc, opt_dec, sched_enc, sched_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a0dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_complete():\n",
    "    ###################  Learning Rate optimizer and Scheduler  ####################################\n",
    "    mn_lr=10**(-5.0)\n",
    "    mx_lr=10**(-4.0)\n",
    "    \n",
    "    opt_enc = torch.optim.Adam(encoder_model.parameters(), lr=mn_lr, \n",
    "                                 betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "    opt_dec = torch.optim.Adam(decoder_model.parameters(), lr=mn_lr, \n",
    "                                 betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "    \n",
    "    \n",
    "    cycle_length=100\n",
    "    sched_enc=torch.optim.lr_scheduler.CyclicLR(opt_enc, base_lr=mn_lr, max_lr=mx_lr, cycle_momentum=False,\n",
    "                                            step_size_up=cycle_length, step_size_down=None, mode='triangular')\n",
    "    \n",
    "    sched_dec=torch.optim.lr_scheduler.CyclicLR(opt_dec, base_lr=mn_lr, max_lr=mx_lr, cycle_momentum=False,\n",
    "                                            step_size_up=cycle_length, step_size_down=None, mode='triangular')\n",
    "    \n",
    "    #################################################################################################\n",
    "    total_batches=len(train_loader) \n",
    "    max_epochs=300\n",
    "    tot_batch_updates_val= 2*cycle_length # check at the end of \"scheduler\" triangles where lr is min.\n",
    "    patience=40 # For Early Stopping\n",
    "    \n",
    "    \n",
    "    ##################### Initialize #################################################################\n",
    "    ptnc_cnt=0 # for Early stopping\n",
    "    flag=0 # 0=> continue, 1=> Early Stopping has occured to break the outer loop for epoch\n",
    "    max_metric=-999 # best val accuracy encountered so far\n",
    "    \n",
    "    cnt=0\n",
    "    \n",
    "    run_loss=0\n",
    "    run_reg_dfrm=0\n",
    "    run_reg_add=0\n",
    "    run_dscimg=0\n",
    "    \n",
    "    run_fld=0\n",
    "    run_smth=0\n",
    "    run_l1=0\n",
    "    \n",
    "    \n",
    "    t2 = time.time()\n",
    "    \n",
    "    for epoch in range(0, max_epochs):\n",
    "        for i, sample in enumerate(train_loader):\n",
    "            cnt=cnt+1\n",
    "            \n",
    "            I_A=sample['I_A']\n",
    "            I_B=sample['I_B']        \n",
    "            IA_msk=sample['IA_msk']\n",
    "            IB_msk=sample['IB_msk']\n",
    "            del sample\n",
    "            \n",
    "            I_A=I_A.to(device)\n",
    "            I_B=I_B.to(device)\n",
    "            IA_msk=IA_msk.to(device)\n",
    "            IB_msk=IB_msk.to(device)\n",
    "            \n",
    "            \n",
    "            loss, reg_loss_dfrm, reg_loss_add,dscrm_loss_img,fld_loss,dfrm_smth_loss,add_l1_loss,opt_enc, opt_dec,\\\n",
    "            sched_enc, sched_dec=train_one_batch(I_A, I_B, IA_msk, IB_msk, opt_enc, opt_dec, sched_enc, sched_dec)\n",
    "            \n",
    "            run_loss=run_loss+loss\n",
    "            run_reg_dfrm=run_reg_dfrm+reg_loss_dfrm\n",
    "            run_reg_add=run_reg_add+reg_loss_add\n",
    "            run_dscimg=run_dscimg+dscrm_loss_img\n",
    "            \n",
    "            run_fld=run_fld+fld_loss\n",
    "            run_smth=run_smth+dfrm_smth_loss \n",
    "            run_l1=run_l1+add_l1_loss\n",
    "            \n",
    "            \n",
    "            del loss,reg_loss_dfrm, reg_loss_add, dscrm_loss_img,fld_loss,dfrm_smth_loss,add_l1_loss\n",
    "            del I_A,I_B,IA_msk, IB_msk\n",
    "            \n",
    "            \n",
    "            if (cnt+1) % 10== 0: # displays after every 10 batch updates\n",
    "                print (\"Epoch [{}/{}], Batch [{}/{}], cnt {}, Train Loss: {:.4f}, REG_DFRM: {:.4f}, REG_ADD: {:.4f}, DSC_REG: {:.4f}, FLD: {:.4f}, L1: {:.4f}, SMTH: {:.4f}\"\n",
    "                       .format(epoch+1, max_epochs, i+1, total_batches, cnt, (run_loss/cnt),(run_reg_dfrm/cnt),(run_reg_add/cnt),\n",
    "                        (run_dscimg/cnt),(run_fld/cnt), (run_l1/cnt),(run_smth/cnt)), end =\"\\r\")\n",
    "                \n",
    "            \n",
    "            ############# Monitor Validation Acc and Early Stopping ############\n",
    "            if cnt>=tot_batch_updates_val:\n",
    "                torch.save({'model_state_dict_encoder_model': encoder_model.state_dict(),\n",
    "                            'model_state_dict_decoder_model': decoder_model.state_dict()}, 'last_weight.pt')\n",
    "                \n",
    "                print('\\n Training time for 1 cycle is: '+str(time.time() - t2) +' seconds')\n",
    "                \n",
    "                # Monitor val auc\n",
    "                metric=complete_inference(val_loader)    \n",
    "                \n",
    "                ########## Reinitialize for next cycle the running loss, optimizer and scheduler\n",
    "                cnt=0\n",
    "    \n",
    "                run_loss=0\n",
    "                run_reg_dfrm=0\n",
    "                run_reg_add=0\n",
    "                run_dscimg=0\n",
    "    \n",
    "                run_fld=0\n",
    "                run_smth=0\n",
    "                run_l1=0\n",
    "                \n",
    "                t2 = time.time()\n",
    "            \n",
    "                # Early Stopping\n",
    "                if metric>max_metric:\n",
    "                    torch.save({'model_state_dict_encoder_model': encoder_model.state_dict(),\n",
    "                            'model_state_dict_decoder_model': decoder_model.state_dict()}\n",
    "                            , 'best_weight'+str(metric)+'.pt')\n",
    "                    max_metric=metric\n",
    "                    ptnc_cnt=0\n",
    "                else:\n",
    "                    ptnc_cnt=ptnc_cnt+1\n",
    "                    print('\\n Validation metric has not improved in last '+str(ptnc_cnt)+' batch updates')\n",
    "                    if ptnc_cnt>=patience:\n",
    "                        print(\"\\n Early Stopping ! from current epoch \\n \\n\")\n",
    "                        flag=1 # this will be used to break out of the outer loop for epochs.\n",
    "                        break # this breaks out of inner loop of Dataloader\n",
    "        if flag==1: # Early Stopping has ocurred\n",
    "            break # break out of the outer loop for epochs.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ef255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308573a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453db9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=10**(-14)\n",
    "grid_4=create_mesh_grid(192,192,32) # Spatial index used to apply the spatial deformation\n",
    "\n",
    "############### Dataloader #####################\n",
    "# see comments in /Dataloader/MorphSSL_dataloader.py  for img_pth, img_pairs\n",
    "train_data=train_dataset(img_pth='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/preprocessed_SSL_images2/',\n",
    "                         img_pairs='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/step4_final_train_ssl_data.npz')\n",
    "train_loader=DataLoader(dataset=train_data, batch_size=1, shuffle=True, num_workers=2, \n",
    "                             pin_memory=False, drop_last=False, worker_init_fn=worker_init_fn)\n",
    "\n",
    "val_data=val_dataset(img_pth='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/preprocessed_SSL_images2/',\n",
    "                     img_pairs='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/step4_final_val_ssl_data.npz')\n",
    "val_loader=DataLoader(dataset=val_data, batch_size=1, shuffle=False, num_workers=2, \n",
    "                             pin_memory=False, drop_last=False, worker_init_fn=worker_init_fn)\n",
    "\n",
    "\n",
    "########### Instantiate the Models ##############\n",
    "#### Encoder ###\n",
    "encoder_model=Encoder_Architecture(base_chnls=16, out_ftr_dim=(64*2))\n",
    "encoder_model.to(device)\n",
    "#### Decoder ###\n",
    "decoder_model=Decoder_Architecture(in_dim=64, first_dim=512)\n",
    "decoder_model.to(device)\n",
    "#### Comparator ###\n",
    "comparator_model=Comparator_Architecture(base_chnls=16, out_ftr_dim=(64*2))   \n",
    "comparator_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Begin Training #########\n",
    "train_complete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
