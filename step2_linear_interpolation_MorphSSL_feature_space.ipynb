{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03285fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.getcwd()+'/model/')\n",
    "sys.path.append(os.getcwd()+'/losses/')\n",
    "sys.path.append(os.getcwd()+'/Dataloader/')\n",
    "\n",
    "\n",
    "from Encoder_model import *\n",
    "from Decoder_model import *\n",
    "from Comparator_model import *\n",
    "from Dense_Spatial_Transformation import * \n",
    "#from Inference_MorphSSL import *\n",
    "from MorphSSL_dataloader import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9e00c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_normalize(I):\n",
    "    I=I.astype(float)\n",
    "    I=I-np.min(I)\n",
    "    I=I/np.max(I)\n",
    "    I=I*255\n",
    "    I=I.astype(np.uint8)\n",
    "    \n",
    "    return I\n",
    "\n",
    "def my_normalize_scale(I):\n",
    "    \n",
    "    I=I.astype(float)\n",
    "    I=np.abs(I)\n",
    "    I=I/np.max(I)\n",
    "    I=I*255\n",
    "    I=I.astype(np.uint8)\n",
    "    \n",
    "    return I\n",
    "\n",
    "\n",
    "\n",
    "def my_visualize(out_lst,nm):\n",
    "    \n",
    "    out_col=[]\n",
    "    for j in range(0, len(out_lst)):\n",
    "        tmp=out_lst[j]\n",
    "        tmp=tmp.detach().cpu().numpy()\n",
    "        tmp=np.squeeze(tmp)\n",
    "        tmp=my_normalize(tmp)\n",
    "        \n",
    "        out_row=[]\n",
    "        for slc in range(0,4):\n",
    "            out_row.append(tmp[:,:,slc])\n",
    "            pad=255*np.ones((30, tmp.shape[1])).astype(np.uint8)\n",
    "            out_row.append(pad)\n",
    "        # Concat along row\n",
    "        out_row=np.concatenate(out_row, axis=0)\n",
    "        out_col.append(out_row)\n",
    "        pad=255*np.ones((out_row.shape[0],30)).astype(np.uint8)\n",
    "        out_col.append(pad)\n",
    "        \n",
    "    out_col=np.concatenate(out_col, axis=1)\n",
    "    # save image\n",
    "    io.imsave(nm, out_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1753f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(I_A, I_B, nm):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ftr_A=encoder_model(I_A) # time t\n",
    "        ftr_B=encoder_model(I_B) # time t+k\n",
    "        \n",
    "    out_lst=[]\n",
    "    out_lst.append(I_A[:,:,:,:,15:19]) # Only visualize the central 4 B-scans instead of all 32 B-scans in the volume\n",
    "    for k in [0.2, 0.4, 0.6, 0.8, 1.0]: # could be changed as per requirement\n",
    "        ftr_new=ftr_A+k*(ftr_B-ftr_A)\n",
    "        D_AB, C_AB=decoder_model(ftr_A, ftr_new)\n",
    "        I_out, _=spatial_transform(I_A, D_AB, grid_4,'nearest')\n",
    "        I_out=I_out+C_AB\n",
    "        out_lst.append(I_out[:,:,:,:,15:19])\n",
    "        del D_AB, C_AB, ftr_new, I_out\n",
    "    \n",
    "    out_lst.append(I_B[:,:,:,:,15:19])\n",
    "    my_visualize(out_lst,nm)\n",
    "    return \n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "def visualize_linear_interpolation(val_loader, out_pth):  \n",
    "    decoder_model.eval()\n",
    "    encoder_model.eval()\n",
    "    \n",
    "    for i, sample in enumerate(val_loader):\n",
    "        print(i)\n",
    "                \n",
    "        I_A=sample['I_A']\n",
    "        I_B=sample['I_B']\n",
    "        \n",
    "        nm_A=sample['nm_A'][0]\n",
    "        nm_B=sample['nm_B'][0]\n",
    "        \n",
    "        nm=nm_A+'_'+nm_B+'.png'\n",
    "        \n",
    "        I_A=I_A.to(device)\n",
    "        I_B=I_B.to(device)\n",
    "        \n",
    "        inference(I_A, I_B, out_pth+nm)\n",
    "        del I_A, I_B\n",
    "    \n",
    "   \n",
    "    return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064b34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc23693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141da236",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps=10**(-14)\n",
    "grid_4=create_mesh_grid(192,192,32) # Spatial index used to apply the spatial deformation\n",
    "\n",
    "############### Dataloader #####################\n",
    "# see comments in /Dataloader/MorphSSL_dataloader.py  for img_pth, img_pairs\n",
    "val_data=val_dataset(img_pth='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/preprocessed_SSL_images2/',\n",
    "                     img_pairs='/msc/home/achakr83/PINNACLE/SSL_training/May30/final_full_training/step4_final_val_ssl_data.npz')\n",
    "val_loader=DataLoader(dataset=val_data, batch_size=1, shuffle=False, num_workers=2, \n",
    "                             pin_memory=False, drop_last=False, worker_init_fn=worker_init_fn)\n",
    "\n",
    "\n",
    "########### Instantiate the Models ##############\n",
    "#### Encoder ###\n",
    "encoder_model=Encoder_Architecture(base_chnls=16, out_ftr_dim=(64*2))\n",
    "encoder_model.to(device)\n",
    "#### Decoder ###\n",
    "decoder_model=Decoder_Architecture(in_dim=64, first_dim=512)\n",
    "decoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e198364",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('best_weight-0.007980789116118103.pt')\n",
    "encoder_model.load_state_dict(checkpoint['model_state_dict_encoder_model'])\n",
    "decoder_model.load_state_dict(checkpoint['model_state_dict_deform_model']) #or model_state_dict_decoder_model\n",
    "del checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pth=os.getcwd()+'/visualize_linear_interpolation/'\n",
    "if not os.path.exists(out_pth):\n",
    "    os.makedirs(out_pth)\n",
    "\n",
    "visualize_linear_interpolation(val_loader, out_pth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
